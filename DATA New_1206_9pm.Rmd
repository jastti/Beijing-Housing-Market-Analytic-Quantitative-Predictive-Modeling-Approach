---
title: "Final Project part1"
author: "Group"
date: "2023-10-02"
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
install.packages("car")
library(readr)
set.seed(1417)
library(dplyr)
library(car)


```

```{r}
Housing <- read_csv("new.csv",show_col_types = FALSE)
Housing = na.omit(Housing)

#write.csv(Housing, "/home/jovyan/STA302/Final Project\\Cleaned_Data.csv", row.names=FALSE)
```

```{r}





Housing = Housing %>% mutate(Elevator_C = case_when(elevator == 0 ~ "No",
                                              elevator == 1 ~ "Yes"),
                       Subway_C = case_when(subway == 0 ~"No",
                                            subway == 1 ~ "Yes"),
                       building_type = case_when(buildingType ==1 ~ "tower",
                                                 buildingType ==2 ~"bungalow",
                                                 buildingType == 3 ~ "com_plat_tower",
                                                 buildingType == 4 ~ "plate"))
summary(Housing)

```

```{r}
Housing %>% filter(elevator==0 | elevator==1) %>% 
  group_by(elevator) %>% 
  summarise(num_lines = n()
       )

Housing %>% filter(subway==0 | subway==1) %>% 
  group_by(subway) %>% 
  summarise(num_lines = n()
       )
Housing %>% filter(buildingType==1 | buildingType==2| buildingType==3| buildingType==4) %>% 
  group_by(buildingType) %>% 
  summarise(num_lines = n()
       )
B = Housing %>% select(square,livingRoom ,drawingRoom , kitchen , bathRoom , ladderRatio )
summary(B,na.rm=TRUE)
```

```{r}
less_housing_data1 = sample_n(Housing, 30000, replace = FALSE)
less_housing_data = na.omit(less_housing_data1)
fit = lm(price ~  square + livingRoom + drawingRoom + kitchen + bathRoom + building_type + ladderRatio + Elevator_C + Subway_C, 
         data = less_housing_data)
write.csv(less_housing_data, "actually use data")

```

```{r}
summary(fit)$coefficients
```

$$\hat{y}_{price} = 83536.1 -217.9 x_{square} + 3920.4x_{livingroom} -766.5x_{drawingroom} + 13145.1x_{kitchen}+5385.0x_{bathroom} -49184.3x_{BT -plate-and-tower}-49328.5x_{BT-plate}-50328.0x_{BT-tower} +1901.3x_{ladderRatio} +4050.2x_{Elevator-Yes} +11236.0x_{Subway-Yes}$$

$$\hat{y}_{price} = \hat{\beta_0} + \hat{\beta_1} x_{square} + \hat{ \beta_2}x_{livingroom} + \hat{\beta_3}x_{drawingroom} + \hat{\beta_4}x_{kitchen}+\hat{\beta_5}x_{bathroom} + \hat{\beta_6}x_{BT -plate-and-tower}+\hat{\beta_7}x_{BT-plate}+\hat{\beta_8}x_{BT-tower} +\hat{\beta_9}x_{ladderRatio} +\hat{\beta_{10}}x_{Elevator-Yes} +\hat{\beta_{11}}x_{Subway-Yes}$$

```{r}
resid(fit)
```

```{r}
rstandard(fit)
```

## Residual against fitted value

```{r}
fitted_values = fitted(fit)
residual_values = resid(fit)
     
plot(fitted_values, residual_values, 
     main = "Housing Price of Beijing: fitted versus residual values", 
     xlab = "Fitted", 
     ylab = "Residuals")
```

```{r}
plot(fit, which=1)
```

## Standardized residual against fitted value in scatter plot

```{r}
fitted_values = fitted(fit)
sresidual_values = rstandard(fit)
     
plot(fitted_values, sresidual_values, 
     main = "Housing Price of Beijing: fitted versus residual values", 
     xlab = "Fitted", 
     ylab = "Standardize Residuals")
```

```{r}
plot(fit, which=3)
```

## Standardized residual against fitted value in histogram

```{r}
hist(sresidual_values,
     main = "Standardized residuals histogram",
     xlab = "Standardized residuals")
```

## Residual plots for square predictors

```{r}
a = log(less_housing_data$square)
plot(a, residual_values, main = "Residual vs square", xlab = "square", ylab = "Residual")
```

## Residual plot for the living room

```{r}
plot(residual_values ~ less_housing_data$livingRoom, main = "Residual vs livingRoom", xlab = "livingRoom", ylab = "Residual")
```

## Residual plot for the drawingroom

```{r}
plot(residual_values ~ less_housing_data$drawingRoom, main = "Residual vs drawingroom", xlab = "drawingroom", ylab = "Residual")
```

## Residual plot for the kitchen

```{r}
plot(residual_values ~ less_housing_data$kitchen, main = "Residual vs kitchen", xlab = "kitchen", ylab = "Residual")
```

## Residual plot for the bathroom

```{r}
plot(residual_values ~ less_housing_data$bathRoom, main = "Residual vs bathroom", xlab = "bathroom", ylab = "Residual")
```

## Residual plot for the buildingtype

```{r}
plot(residual_values ~ less_housing_data$buildingType, main = "Residual vs buildingtype", xlab = "buildingtype,\n where tower(1.0) , bungalow(2.0)ï¼Œcombination of plate and tower(3.0), plate(4.0)", ylab = "Residual")
```

## Residual plot for the ladder ratio

```{r}
plot(residual_values ~ less_housing_data$ladderRatio, main = "Residual vs ladder ratio", xlab = "ladder ratio", ylab = "Residual")
```

## residual for elevator in boxplot

```{r}
boxplot(residual_values ~ less_housing_data$Elevator_C, main = "Residual by elevator", xlab = "elevator", ylab = "Residual", names = (c("0: no elevator", "1: have elevator")))
```

## residual for subway in boxplot

```{r}
boxplot(residual_values ~ less_housing_data$Subway_C, main = "Residual by subway", xlab = "subway", ylab = "Residual", names = (c("0: no subway", "1: have subway")))
```

## QQplot for residual

```{r}
qqnorm(residual_values)
qqline(residual_values)
```

## Lecture 2: Checking the linearity assumption

```{r}
plot(less_housing_data[, c(10, 11, 12)], col="cadetblue")

plot(less_housing_data[, c(13, 14, 15)], col="cadetblue")

plot(less_housing_data[, c( 17, 21, 22, 24)], col="cadetblue")


```

```{r}
#module10: Difference analytical approaches (overfitting and validation)
#find out the training data and the testing data; with ratio 50% and 50%
#Test data: test, training data: train
#For M1
s <- sample(1:nrow(less_housing_data), 10000, replace = FALSE)
train_data <- less_housing_data[s,]
test_data <- less_housing_data[-s,]
model_train <- lm(price ~  square + livingRoom + drawingRoom + kitchen + bathRoom + building_type + ladderRatio + Elevator_C + Subway_C, 
         data = train_data)
model_test <- lm(price ~  square + livingRoom + drawingRoom + kitchen + bathRoom + building_type + ladderRatio + Elevator_C + Subway_C, 
         data = test_data)
summary(model_test)
summary(model_train)
vif(model_train)
vif(model_test)
#Conclusion:
#compare on the summary of train and test:
# number of significant: train: 11; test: 7, they are not so similar
# different estimates of each coefficients and they are within 2SE
# the R_adj for training is: 0.1062, and the R_adj for testing data is: 0.1173, which are similar.
# after comparing the vifs of training and testing, we can find the vifs are similar.

#For M2
s <- sample(1:nrow(less_housing_data), 10000, replace = FALSE)
train_data <- less_housing_data[s,]
test_data <- less_housing_data[-s,]
model_train <- lm(price ~  square + livingRoom + drawingRoom + kitchen + bathRoom + building_type +  Elevator_C + Subway_C, 
         data = train_data)
model_test <- lm(price ~  square + livingRoom + drawingRoom + kitchen + bathRoom + building_type +  Elevator_C + Subway_C, 
         data = test_data)
summary(model_test)
summary(model_train)
vif(model_train)
vif(model_test)

#For M3
s <- sample(1:nrow(less_housing_data), 10000, replace = FALSE)
train_data <- less_housing_data[s,]
test_data <- less_housing_data[-s,]
model_train <- lm(price ~  square + livingRoom + drawingRoom + kitchen + bathRoom  +  Elevator_C + Subway_C, 
         data = train_data)
model_test <- lm(price ~  square + livingRoom + drawingRoom + kitchen + bathRoom  +  Elevator_C + Subway_C, 
         data = test_data)
summary(model_test)
summary(model_train)
vif(model_train)
vif(model_test)

#For M4
s <- sample(1:nrow(less_housing_data), 10000, replace = FALSE)
train_data <- less_housing_data[s,]
test_data <- less_housing_data[-s,]
model_train <- lm(price ~  square + livingRoom + drawingRoom + kitchen + bathRoom +  ladderRatio + Elevator_C + Subway_C, 
         data = train_data)
model_test <- lm(price ~  square + livingRoom + drawingRoom + kitchen + bathRoom +  ladderRatio + Elevator_C + Subway_C, 
         data = test_data)
summary(model_test)
summary(model_train)
vif(model_train)
vif(model_test)
```

##comparing the residue plots for training and testing:

```{r}
#Residue for training:
residual_values_training = resid(model_train)
#residue for testing:
residual_values_testing = resid(model_test)
```

## Residual plots for square predictors

```{r}
a = log(train_data$square)
plot(a, residual_values_training, main = "Residual vs square", xlab = "square", ylab = "Residual")
```

```{r}
a = log(test_data$square)
plot(a, residual_values_testing, main = "Residual vs square", xlab = "square", ylab = "Residual")
```

## Residual plot for the living room

```{r}
plot(residual_values_training ~ train_data$livingRoom, main = "Residual vs livingRoom", xlab = "livingRoom", ylab = "Residual")
```

```{r}
plot(residual_values_testing ~ test_data$livingRoom, main = "Residual vs livingRoom", xlab = "livingRoom", ylab = "Residual")
```

## Residual plot for the drawingroom

```{r}
plot(residual_values_training ~ train_data$drawingRoom, main = "Residual vs drawingroom", xlab = "drawingroom", ylab = "Residual")
```

```{r}
plot(residual_values_testing ~ test_data$drawingRoom, main = "Residual vs drawingroom", xlab = "drawingroom", ylab = "Residual")
```

## Residual plot for the kitchen

```{r}
plot(residual_values_training ~ train_data$kitchen, main = "Residual vs kitchen", xlab = "kitchen", ylab = "Residual")
```

```{r}
plot(residual_values_testing ~ test_data$kitchen, main = "Residual vs kitchen", xlab = "kitchen", ylab = "Residual")
```

## Residual plot for the bathroom

```{r}
plot(residual_values_training ~ train_data$bathRoom, main = "Residual vs bathroom", xlab = "bathroom", ylab = "Residual")
```

```{r}
plot(residual_values_testing ~ test_data$bathRoom, main = "Residual vs bathroom", xlab = "bathroom", ylab = "Residual")
```

## Residual plot for the buildingtype

```{r}
plot(residual_values_training ~ train_data$buildingType, main = "Residual vs buildingtype", xlab = "buildingtype,\n where tower(1.0) , bungalow(2.0)ï¼Œcombination of plate and tower(3.0), plate(4.0)", ylab = "Residual")
```

```{r}
plot(residual_values_testing ~ test_data$buildingType, main = "Residual vs buildingtype", xlab = "buildingtype,\n where tower(1.0) , bungalow(2.0)ï¼Œcombination of plate and tower(3.0), plate(4.0)", ylab = "Residual")
```

## Residual plot for the ladder ratio

```{r}
plot(residual_values_training ~ train_data$ladderRatio, main = "Residual vs ladder ratio", xlab = "ladder ratio", ylab = "Residual")
```

```{r}
plot(residual_values_testing ~ test_data$ladderRatio, main = "Residual vs ladder ratio", xlab = "ladder ratio", ylab = "Residual")
```

## residual for elevator in boxplot

```{r}
boxplot(residual_values_training ~ train_data$Elevator_C, main = "Residual by elevator", xlab = "elevator", ylab = "Residual", names = (c("0: no elevator", "1: have elevator")))
```

```{r}
boxplot(residual_values_testing ~ test_data$Elevator_C, main = "Residual by elevator", xlab = "elevator", ylab = "Residual", names = (c("0: no elevator", "1: have elevator")))
```

## QQplot for residual

```{r}
qqnorm(residual_values_training)
qqline(residual_values_training)
```

```{r}
qqnorm(residual_values_testing)
qqline(residual_values_testing)
```

Module 8 plots

```{r}
#fit = lm(price ~  square + livingRoom + drawingRoom + kitchen + bathRoom + building_type + ladderRatio + Elevator_C + Subway_C, 
#         data = less_housing_data)

#detect the outlier for x=square
ps_model <- lm(price ~ square, less_housing_data)
plot(ps_model, which = 1)
#hatvalues(ps_model)

#detect the outlier for x=livingRoom
pl_model <- lm(price ~ livingRoom, less_housing_data)
plot(pl_model, which = 1)

#detect the outlier for x=kitchen
pk_model <- lm(price ~ kitchen, less_housing_data)
plot(pk_model, which = 1)

#detect the outlier for x=bathRoom
pb_model <- lm(price ~ bathRoom, less_housing_data)
plot(pb_model, which = 1)

#detect the outlier for x=building_type
pbt_model <- lm(price ~ building_type, less_housing_data)
plot(pbt_model, which = 1)

#detect the outlier for x=ladderRatio
plr_model <- lm(price ~ ladderRatio, less_housing_data)
plot(plr_model, which = 1)

#detect the outlier for x=Elevator_C
pec_model <- lm(price ~ Elevator_C, less_housing_data)
plot(pec_model, which = 1)

#detect the outlier for x=Subway_C
psc_model <- lm(price ~ Subway_C, less_housing_data)
plot(psc_model, which = 1)
```

Get Cook's distances $D_i$
```{r}
cooks.distance(fit)

plot(fit, which = 4)

#All diagnostic plots for model 1
# Recall that model1 is fit = lm(price ~  square + livingRoom + drawingRoom + kitchen + bathRoom + building_type + ladderRatio + Elevator_C + Subway_C, data = less_housing_data)
par(mfrow = c(2, 2))
plot(fit, which = c(1, 2, 3, 4))

# model 2: ladder ratio is deleted from model 1, and draw all diagnostic plots for model 2
fit2 = lm(price ~  square + livingRoom + drawingRoom + kitchen + bathRoom + building_type + Elevator_C + Subway_C, data = less_housing_data)
par(mfrow = c(2, 2))
plot(fit2, which = c(1, 2, 3, 4))


# model 3: ladder ratio and building type are deleted from model 1, and draw all diagnostic plots for model 3
fit3 = lm(price ~  square + livingRoom + drawingRoom + kitchen + bathRoom + Elevator_C + Subway_C, data = less_housing_data)
par(mfrow = c(2, 2))
plot(fit3, which = c(1, 2, 3, 4))

# model 4: building type is deleted from model 1, and draw all diagnostic plots for model 4
fit4 = lm(price ~  square + livingRoom + drawingRoom + kitchen + bathRoom + ladderRatio + Elevator_C + Subway_C, data = less_housing_data)
par(mfrow = c(2, 2))
plot(fit2, which = c(1, 2, 3, 4))
```

Compute influence measures in R
```{r}
dfbetas(fit)

dffits(fit)
```

```{r}
#calculate the AIC and BIC of the three models:
#model 1:
p = length(coef(fit)) - 1
n = nrow(less_housing_data)
cbind(summary(fit)$adj.r.squared, extractAIC(fit, k = 2)[2], extractAIC(fit, k = log(n))[2], extractAIC(fit, k = 2)[2] + (2*(p+2)*(p+3)/(n-p-1)))




#model 2:
p = length(coef(fit2)) - 1
n = nrow(less_housing_data)
cbind(summary(fit2)$adj.r.squared, extractAIC(fit2, k = 2)[2], extractAIC(fit2, k = log(n))[2], extractAIC(fit2, k = 2)[2] + (2*(p+2)*(p+3)/(n-p-1)))




#model3
p = length(coef(fit3)) - 1
n = nrow(less_housing_data)
cbind(summary(fit3)$adj.r.squared, extractAIC(fit3, k = 2)[2], extractAIC(fit3, k = log(n))[2], extractAIC(fit3, k = 2)[2] + (2*(p+2)*(p+3)/(n-p-1)))



#model4
p = length(coef(fit4)) - 1
n = nrow(less_housing_data)
cbind(summary(fit4)$adj.r.squared, extractAIC(fit4, k = 2)[2], extractAIC(fit4, k = log(n))[2], extractAIC(fit4, k = 2)[2] + (2*(p+2)*(p+3)/(n-p-1)))



```



```{r}
#trial of backward selection method:

#install.packages("MASS")
#library(MASS)
#stepAIC(lm(price ~ ., data = less_housing_data[, -1]), 
 #       scope = list(lower = lm(price ~ 9, less_housing_data[, -1])),
  #      direction = "backward", k = 2)
```

